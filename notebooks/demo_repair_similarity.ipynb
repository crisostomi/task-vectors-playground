{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/data/datamodule.py:193: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import Callback\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "from nn_core.common.utils import enforce_tags, seed_index_everything\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "\n",
    "# Force the execution of __init__.py if this file is executed directly.\n",
    "import tvp  # noqa\n",
    "from tvp.data.datamodule import MetaData\n",
    "from tvp.data.datasets.registry import get_dataset\n",
    "from tvp.task_vectors.task_vectors import TaskVector\n",
    "from tvp.utils.io_utils import load_model_from_artifact\n",
    "from tvp.utils.utils import build_callbacks\n",
    "from torch.nn.utils import vector_to_parameters\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pylogger = logging.getLogger(__name__)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"task_vectors\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1608637542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:16:47 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Setting seed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608637542</span> from seeds<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:16:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Setting seed \u001b[1;36m1608637542\u001b[0m from seeds\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                         \u001b]8;id=506654;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=125355;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tags: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'dev'</span><span style=\"font-weight: bold\">]</span>                                                  <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">96</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tags: \u001b[1m[\u001b[0m\u001b[32m'dev'\u001b[0m\u001b[1m]\u001b[0m                                                  \u001b]8;id=507214;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552910;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Restoring with mode: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"font-weight: bold\">&gt;</span>                                         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.resume</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Restoring with mode: \u001b[1m<\u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1m>\u001b[0m                                         \u001b]8;id=346224;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\u001b\\\u001b[2mnn_core.resume\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130475;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\u001b\\\u001b[2m122\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">WandbLogger</span><span style=\"font-weight: bold\">&gt;</span>                                   <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.model_logging</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating \u001b[1m<\u001b[0m\u001b[1;95mWandbLogger\u001b[0m\u001b[1m>\u001b[0m                                   \u001b]8;id=170108;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\u001b\\\u001b[2mnn_core.model_logging\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=507338;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Failed to detect the name of this notebook, you can set it manually  <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">wandb.jupyter</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py#224\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         with the WANDB_NOTEBOOK_NAME environment variable to enable code     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         saving.                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Failed to detect the name of this notebook, you can set it manually  \u001b]8;id=25814;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py\u001b\\\u001b[2mwandb.jupyter\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=720665;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py#224\u001b\\\u001b[2m224\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         with the WANDB_NOTEBOOK_NAME environment variable to enable code     \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         saving.                                                              \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdansolombrino\u001b[0m (\u001b[33mgladia\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240530_141648-dqnza2fw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gladia/task-vectors-playground/runs/dqnza2fw' target=\"_blank\">wise-sunset-188</a></strong> to <a href='https://wandb.ai/gladia/task-vectors-playground' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gladia/task-vectors-playground' target=\"_blank\">https://wandb.ai/gladia/task-vectors-playground</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gladia/task-vectors-playground/runs/dqnza2fw' target=\"_blank\">https://wandb.ai/gladia/task-vectors-playground/runs/dqnza2fw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "cfg.core.tags = enforce_tags(cfg.core.get(\"tags\", None))\n",
    "\n",
    "template_core: NNTemplateCore = NNTemplateCore(\n",
    "    restore_cfg=cfg.train.get(\"restore\", None),\n",
    ")\n",
    "logger: NNLogger = NNLogger(logging_cfg=cfg.train.logging, cfg=cfg, resume_id=template_core.resume_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResetConv(nn.Module):\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        self.out_channels = conv.out_channels\n",
    "        self.conv = conv\n",
    "        self.bn = nn.BatchNorm2d(self.out_channels)\n",
    "        self.rescale = False\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_var, eps=1e-5):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        goal_std = (goal_var + eps).sqrt()\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.rescale:\n",
    "            x = self.bn(x)\n",
    "        else:\n",
    "            self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ResetLinear(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        # print(f\"\\n\\n[ResetLinear] layer: {layer}\\n\\n\")\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.out_features)\n",
    "        self.weight = layer.weight\n",
    "        self.bias = layer.bias\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [L, N, C] (in torch.nn.BatchNorm1d doc notation)\n",
    "        x = self.layer(x)\n",
    "\n",
    "        # match current shape to shape required by BatchNorm1d\n",
    "        x = x.permute(1, 2, 0)\n",
    "        # x.shape: [N, C, L] (in torch.nn.BatchNorm1d doc notation)\n",
    "        \n",
    "        x = self.bn(x)\n",
    "\n",
    "        # match current shape to shape required by Linear\n",
    "        x = x.permute(2, 0, 1)\n",
    "        # x.shape: [L, N, C] (in torch.nn.BatchNorm1d doc notation)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class ResetLayerNorm(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.normalized_shape[0])\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "def replace_layers(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, ResetConv(child))\n",
    "        # elif isinstance(child, nn.LayerNorm):\n",
    "        #     setattr(module, name, ResetLayerNorm(child))\n",
    "        elif isinstance(child, nn.Linear):\n",
    "            setattr(module, name, ResetLinear(child))\n",
    "        else:\n",
    "            replace_layers(child)\n",
    "\n",
    "\n",
    "def make_tracked_net(model):\n",
    "    tracked_model = copy.deepcopy(model)\n",
    "    replace_layers(tracked_model.model.visual)\n",
    "    return tracked_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_task_statistics(model, endpoint_models):\n",
    "#     for m_interp, *endpoint_modules in zip(model_to_repair.modules(), *[model.modules() for model in endpoint_models]):\n",
    "#         if isinstance(m_interp, (ResetConv, ResetLayerNorm, ResetLinear)):\n",
    "#             mu_endpoints = torch.stack([m.bn.running_mean for m in endpoint_modules])\n",
    "#             goal_mean = mu_endpoints.mean(dim=0)\n",
    "#             var_endpoints = torch.stack([m.bn.running_var for m in endpoint_modules])\n",
    "#             goal_var = var_endpoints.mean(dim=0)\n",
    "#             m_interp.set_stats(goal_mean, goal_var)\n",
    "#             m_interp.rescale = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap and compute stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def reset_bn_stats(model, epochs, loader):\n",
    "    \"\"\"\n",
    "    Reset batchnorm stats. We use the train loader with data augmentation as this gives better results.\n",
    "    \"\"\"\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None  # use simple average\n",
    "            m.reset_running_stats()\n",
    "\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(list(loader)):\n",
    "                if isinstance(batch, Dict):\n",
    "                    input = batch[\"x\"]\n",
    "                else:\n",
    "                    input = batch[0]\n",
    "                    # print(f\"[reset_bn_stats] input.shape before model(): {input.shape}\")\n",
    "                out = model(input.cuda())\n",
    "                # print(f\"[reset_bn_stats] out.shape after model()   : {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'CIFAR100'\n",
    "dataset_name = cfg.nn.data.train_dataset.replace('Val', '')\n",
    "finetuned_model = finetuned_models[dataset_name]\n",
    "tracked_finetuned_model = make_tracked_net(finetuned_models[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_bn_stats(tracked_finetuned_model.cuda(), 1, dataset.train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_finetuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters()) \n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_task_vector(model, task_vector):\n",
    "    model.load_state_dict({k: v + task_vector[k] for k, v in model.state_dict().items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack([flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model) \n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{cfg.nn.data.dataset.dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=model.encoder.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylogger.info(\"Evaluating on the training set\")\n",
    "# trainer.test(model=model, dataloaders=dataset.train_loader)\n",
    "\n",
    "pylogger.info(\"Evaluating on the test set!\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this accuracy in mind, as it will be used as baseline to compare all upcoming experiments against"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset stats\n",
    "\n",
    "Compute and export mean and std for every dataset, if not already present on disk.<br>\n",
    "Otherwhise, load mean and std for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the full path of a module\n",
    "def get_module_path(module, parent_name=\"\"):\n",
    "    if parent_name:\n",
    "        return f\"{parent_name}.{module._get_name()}\"\n",
    "    return module._get_name()\n",
    "\n",
    "\n",
    "# Define a recursive function to collect batch norm stats from 'Reset' layers\n",
    "def collect_bn_stats(model, parent_name=\"\"):\n",
    "    bn_stats = {}\n",
    "    for name, module in model.named_children():\n",
    "        # Construct the full path of the current module\n",
    "        module_path = f\"{parent_name}.{name}\" if parent_name else name\n",
    "        \n",
    "        # Check for batch normalization layers within Reset layers\n",
    "        if isinstance(module, ResetConv) or isinstance(module, ResetLinear):\n",
    "            for sub_name, sub_module in module.named_children():\n",
    "                if isinstance(sub_module, nn.BatchNorm2d) or isinstance(sub_module, nn.BatchNorm1d):\n",
    "                    bn_stats[f\"{module_path}.{sub_name}\"] = {\n",
    "                        \"running_mean\": sub_module.running_mean.clone().detach(),\n",
    "                        \"running_var\": sub_module.running_var.clone().detach(),\n",
    "                        \"num_batches_tracked\": sub_module.num_batches_tracked.clone().detach()\n",
    "                    }\n",
    "        # Recursively check submodules\n",
    "        bn_stats.update(collect_bn_stats(module, module_path))\n",
    "    \n",
    "    return bn_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stats = {} # S in board pictures\n",
    "\n",
    "# if \"./dataset_stats.pth\" is on disk, do not compute stats!\n",
    "populate_stats = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_stats: \n",
    "\n",
    "    # TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "    import copy\n",
    "\n",
    "    zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "    zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "    finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "    finetuned_models = {\n",
    "        dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "        for dataset in cfg.task_vectors.to_apply\n",
    "    }\n",
    "\n",
    "    zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset stats from './dataset_stats.pth'...\n"
     ]
    }
   ],
   "source": [
    "if populate_stats:\n",
    "\n",
    "    for dataset_name in cfg.task_vectors.to_apply:\n",
    "\n",
    "        print(f\"[dataset_name]: {dataset_name}\\n\")\n",
    "        \n",
    "        # begin load the dataset\n",
    "\n",
    "        dataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            preprocess_fn=zeroshot_model.train_preprocess,\n",
    "            location=cfg.nn.data.data_path,\n",
    "            batch_size=cfg.nn.data.batch_size.train,\n",
    "        )\n",
    "\n",
    "        #   end load the dataset\n",
    "\n",
    "        # begin compute and apply dataset task vector\n",
    "\n",
    "        flatten = lambda model: parameters_to_vector(model.parameters()) \n",
    "\n",
    "        zeroshot_vec = flatten(zeroshot_model)\n",
    "\n",
    "        task_vector = TaskVector.from_models(zeroshot_model, finetuned_models[dataset_name])\n",
    "\n",
    "        task_vector = flatten(finetuned_models[dataset_name]) - zeroshot_vec\n",
    "\n",
    "        # no need to do task_vector_sum-related stuff, as for this step we apply just one task vector\n",
    "\n",
    "        delta_model = copy.deepcopy(zeroshot_model) \n",
    "        vector_to_parameters(task_vector, delta_model.parameters())\n",
    "\n",
    "        task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "        apply_task_vector(task_equipped_model, delta_model.state_dict())\n",
    "\n",
    "        #   end compute and apply dataset task vector\n",
    "\n",
    "        # begin compute layer-wise statistics\n",
    "\n",
    "        tracked_task_equipped_model = make_tracked_net(task_equipped_model)\n",
    "\n",
    "        reset_bn_stats(tracked_task_equipped_model.cuda(), 1, dataset.train_loader)\n",
    "\n",
    "        #   end compute layer-wise statistics\n",
    "\n",
    "        # begin store layer-wise statistics\n",
    "\n",
    "        dataset_stats[dataset_name] = collect_bn_stats(tracked_task_equipped_model.model.visual)\n",
    "\n",
    "        #   end store layer-wise statistics  \n",
    "\n",
    "    torch.save(dataset_stats, './dataset_stats.pth')\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"Loading dataset stats from './dataset_stats.pth'...\")\n",
    "    \n",
    "    dataset_stats = torch.load('./dataset_stats.pth')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchor_batches = 1\n",
    "\n",
    "anchors = {}\n",
    "\n",
    "populate_anchors = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_anchors: \n",
    "\n",
    "    # TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "    import copy\n",
    "\n",
    "    zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "    zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "    finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "    finetuned_models = {\n",
    "        dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "        for dataset in cfg.task_vectors.to_apply\n",
    "    }\n",
    "\n",
    "    zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchors computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading anchors from './anchors.pth'...\n"
     ]
    }
   ],
   "source": [
    "if populate_anchors:\n",
    "\n",
    "    for dataset_name in cfg.task_vectors.to_apply:\n",
    "\n",
    "        print(f\"[dataset_name]: {dataset_name}\\n\")\n",
    "\n",
    "        dataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            preprocess_fn=zeroshot_model.train_preprocess,\n",
    "            location=cfg.nn.data.data_path,\n",
    "            batch_size=cfg.nn.data.batch_size.train,\n",
    "        )\n",
    "\n",
    "        model: nn.Module = copy.deepcopy(finetuned_models[dataset_name])\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for id, train_batch in enumerate (dataset.train_loader):\n",
    "                    \n",
    "                    if id == n_anchor_batches:                    \n",
    "                        break\n",
    "            \n",
    "                    if isinstance(train_batch, Dict):\n",
    "                        input: torch.Tensor = train_batch[\"x\"]\n",
    "                    else:\n",
    "                        input: torch.Tensor = train_batch[0]\n",
    "\n",
    "                    anchors[dataset_name] = model.cuda()(input.cuda())\n",
    "\n",
    "    torch.save(anchors, './anchors.pth')\n",
    "    \n",
    "else:\n",
    "     \n",
    "    print(f\"Loading anchors from './anchors.pth'...\")\n",
    "    \n",
    "    anchors = torch.load('./anchors.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_tensor = torch.stack([anchors[dataset_name] for dataset_name in anchors.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Cars'),\n",
       " (1, 'CIFAR100'),\n",
       " (2, 'DTD'),\n",
       " (3, 'EuroSAT'),\n",
       " (4, 'GTSRB'),\n",
       " (5, 'MNIST'),\n",
       " (6, 'RESISC45'),\n",
       " (7, 'SVHN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate((anchors.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:09 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_pt:latest                   <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_pt:latest                   \u001b]8;id=663784;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=459697;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_pt:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:13 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:13\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=355368;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=790453;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:16 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_Cars_0:latest               <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:16\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_Cars_0:latest               \u001b]8;id=527597;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234146;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_Cars_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:19 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:19\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=836233;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=748715;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:21 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_CIFAR100_0:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:21\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_CIFAR100_0:latest           \u001b]8;id=650903;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=922805;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_CIFAR100_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:25 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:25\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=351483;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=780251;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:27 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_DTD_0:latest                <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:27\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_DTD_0:latest                \u001b]8;id=219438;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568033;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_DTD_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:30 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:30\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=889220;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=474666;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:32 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_EuroSAT_0:latest            <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_EuroSAT_0:latest            \u001b]8;id=829130;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=168546;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_EuroSAT_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:36 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=315957;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494753;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:38 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_GTSRB_0:latest              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_GTSRB_0:latest              \u001b]8;id=782604;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=182222;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_GTSRB_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:41 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=996500;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=369655;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:44 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_MNIST_0:latest              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_MNIST_0:latest              \u001b]8;id=270984;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=480906;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_MNIST_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:47 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=104463;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=575048;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:49 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_RESISC45_0:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_RESISC45_0:latest           \u001b]8;id=724270;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=330076;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_RESISC45_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:52 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=434389;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=806390;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:55 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_SVHN_0:latest               <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_SVHN_0:latest               \u001b]8;id=229256;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=261810;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_SVHN_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:17:58 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:17:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=673489;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=756732;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "import copy\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"GTSRB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:18:49 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EarlyStopping</span><span style=\"font-weight: bold\">&gt;</span>                                    <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:18:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mEarlyStopping\u001b[0m\u001b[1m>\u001b[0m                                    \u001b]8;id=198602;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=853599;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelCheckpoint</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mModelCheckpoint\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=533169;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=189023;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LearningRateMonitor</span><span style=\"font-weight: bold\">&gt;</span>                              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mLearningRateMonitor\u001b[0m\u001b[1m>\u001b[0m                              \u001b]8;id=525472;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=9035;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">TQDMProgressBar</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mTQDMProgressBar\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=171544;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=215473;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating the <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">&gt;</span>                                                <a href=\"file:///tmp/ipykernel_12722/68171410.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_12722/68171410.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating the \u001b[1m<\u001b[0m\u001b[1;95mTrainer\u001b[0m\u001b[1m>\u001b[0m                                                \u001b]8;id=897653;file:///tmp/ipykernel_12722/68171410.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618577;file:///tmp/ipykernel_12722/68171410.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>        <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m        \u001b]8;id=624341;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=275271;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores      <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores      \u001b]8;id=253708;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=40188;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> IPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> IPUs           <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m IPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m IPUs           \u001b]8;id=755584;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=334816;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs           <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs           \u001b]8;id=150796;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=245074;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">val_check_interval</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">)</span>` was         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         configured so validation will run at the end  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         of the training epoch..                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mval_check_interval\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m` was         \u001b]8;id=11427;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=82049;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         configured so validation will run at the end  \u001b[2m                                        \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         of the training epoch..                       \u001b[2m                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters()) \n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack([flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model) \n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:19:33 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_GTSRB_head:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:19:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_GTSRB_head:latest           \u001b]8;id=373976;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=841189;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classifier'])`.\n"
     ]
    }
   ],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate (naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:19:44 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating on the test set!                                                 <a href=\"file:///tmp/ipykernel_12722/3757995039.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_12722/3757995039.py#1\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:19:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating on the test set!                                                 \u001b]8;id=945946;file:///tmp/ipykernel_12722/3757995039.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=863488;file:///tmp/ipykernel_12722/3757995039.py#1\u001b\\\u001b[2m1\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 99/99 [00:16<00:00,  5.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         acc/test          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.6593032479286194     </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         loss/test         </span><span style=\"color: #800080; text-decoration-color: #800080\">     1.093709945678711     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.6593032479286194    \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        loss/test        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    1.093709945678711    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc/test': 0.6593032479286194, 'loss/test': 1.093709945678711}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pylogger.info(\"Evaluating on the test set!\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (our method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:18 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_pt:latest                   <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:18\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_pt:latest                   \u001b]8;id=441687;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=229309;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_pt:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:20 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:20\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=216409;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=524544;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:23 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_Cars_0:latest               <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:23\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_Cars_0:latest               \u001b]8;id=617627;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=390289;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_Cars_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:26 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:26\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=866583;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=129293;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:28 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_CIFAR100_0:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:28\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_CIFAR100_0:latest           \u001b]8;id=798480;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=501696;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_CIFAR100_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:31 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=511344;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=6362;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:33 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_DTD_0:latest                <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_DTD_0:latest                \u001b]8;id=792590;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=7946;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_DTD_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:36 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=589232;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=138300;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:38 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_EuroSAT_0:latest            <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_EuroSAT_0:latest            \u001b]8;id=394037;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=414586;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_EuroSAT_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:41 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=657989;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=847120;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:43 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_GTSRB_0:latest              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:43\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_GTSRB_0:latest              \u001b]8;id=531913;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=739187;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_GTSRB_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:46 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=569843;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=609246;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:49 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_MNIST_0:latest              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_MNIST_0:latest              \u001b]8;id=979367;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=449397;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_MNIST_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:52 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=373012;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=933505;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:54 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_RESISC45_0:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_RESISC45_0:latest           \u001b]8;id=291264;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=417862;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_RESISC45_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:57 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=665175;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=635746;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:20:59 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_SVHN_0:latest               <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:20:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_SVHN_0:latest               \u001b]8;id=78177;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=948717;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_SVHN_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:21:02 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:21:02\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=841124;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850015;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "import copy\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:21:36 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EarlyStopping</span><span style=\"font-weight: bold\">&gt;</span>                                    <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:21:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mEarlyStopping\u001b[0m\u001b[1m>\u001b[0m                                    \u001b]8;id=784952;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=512812;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelCheckpoint</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mModelCheckpoint\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=417222;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=714568;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LearningRateMonitor</span><span style=\"font-weight: bold\">&gt;</span>                              <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mLearningRateMonitor\u001b[0m\u001b[1m>\u001b[0m                              \u001b]8;id=878282;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=623063;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">TQDMProgressBar</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mTQDMProgressBar\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=245583;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=822971;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating the <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">&gt;</span>                                                <a href=\"file:///tmp/ipykernel_12722/68171410.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_12722/68171410.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating the \u001b[1m<\u001b[0m\u001b[1;95mTrainer\u001b[0m\u001b[1m>\u001b[0m                                                \u001b]8;id=856969;file:///tmp/ipykernel_12722/68171410.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=709535;file:///tmp/ipykernel_12722/68171410.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>        <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m        \u001b]8;id=738881;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=436892;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores      <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores      \u001b]8;id=234317;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418989;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:21:37 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> IPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> IPUs           <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:21:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m IPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m IPUs           \u001b]8;id=172688;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=151710;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs           <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs           \u001b]8;id=339017;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=969111;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">val_check_interval</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">)</span>` was         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         configured so validation will run at the end  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         of the training epoch..                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mval_check_interval\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m` was         \u001b]8;id=137565;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=853712;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         configured so validation will run at the end  \u001b[2m                                        \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         of the training epoch..                       \u001b[2m                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters()) \n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack([flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model) \n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model for REPAIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this here, as the classification head may have layers that may be detected as REPAIRable, even tho we don't want to repair them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_task_equipped_model = make_tracked_net(task_equipped_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate (our method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:22:22 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_GTSRB_head:latest           <a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:22:22\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_GTSRB_head:latest           \u001b]8;id=387970;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=883565;file:///mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classifier'])`.\n"
     ]
    }
   ],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=tracked_task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(similarity: torch.Tensor):\n",
    "    # similarity.shape: [B, M]\n",
    "    \n",
    "    # Get the index of the highest similarity for each element in the batch\n",
    "    max_similarity_indices = torch.argmax(similarity, dim=1)  # shape: [B]\n",
    "\n",
    "    # Perform majority voting\n",
    "    majority_vote = Counter(max_similarity_indices.cpu().numpy()).most_common(1)[0][0]\n",
    "    \n",
    "    return majority_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_based_similarity(batch: torch.Tensor, anchors_tensor: torch.Tensor):\n",
    "    # batch.shape: [B, D]\n",
    "    # anchors_tensor.shape: [M, K, D]\n",
    "\n",
    "    M, K, D = anchors_tensor.shape\n",
    "    B = batch.shape[0]\n",
    "\n",
    "    # Compute centroids of each anchor set\n",
    "    centroids = anchors_tensor.mean(dim=1)  # shape: [M, D]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    # Normalize batch and centroids\n",
    "    batch_norm = F.normalize(batch, p=2, dim=1)  # shape: [B, D]\n",
    "    centroids_norm = F.normalize(centroids, p=2, dim=1)  # shape: [M, D]\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity = torch.mm(batch_norm, centroids_norm.t())  # shape: [B, M]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 99/99 [00:14<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_wise_majority_votes = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate through the test data loader and compute point-to-set distances\n",
    "for id, test_batch in tqdm(list(enumerate(dataset.test_loader))):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if isinstance(test_batch, dict):\n",
    "            input: torch.Tensor = test_batch[\"x\"]\n",
    "        else:\n",
    "            input: torch.Tensor = test_batch[0]\n",
    "\n",
    "        emb = finetuned_models[dataset_name].cuda()(input.cuda())  # [B, D]\n",
    "        # print(f\"[emb]: {emb.shape}\")\n",
    "\n",
    "        similarities = centroid_based_similarity(emb, anchors_tensor)\n",
    "        # print(f\"[similarities]: {similarities.shape}\")\n",
    "\n",
    "        batch_wise_majority_votes.append(majority_voting(similarities))\n",
    "        # print(f\"[majority_vote]: {batch_wise_majority_votes[-1]}\")\n",
    "\n",
    "batch_wise_majority_votes = np.asarray(batch_wise_majority_votes)\n",
    "most_similar_dataset_id = Counter(batch_wise_majority_votes).most_common(1)[0][0]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GTSRB'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_dataset = list(anchors.keys())[most_similar_dataset_id]\n",
    "most_similar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_dataset = get_dataset(\n",
    "    dataset_name=most_similar_dataset,\n",
    "    preprocess_fn=model.encoder.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0329, -0.2029, -0.0214, -0.0393, -0.0250, -0.0440, -0.0327, -0.0504,\n",
       "        -0.0188, -0.0048])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean[:10] # should be all zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 209/209 [00:47<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(model.cuda(), 1, most_similar_dataset.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0329, -0.2029, -0.0214, -0.0393, -0.0250, -0.0440, -0.0327, -0.0504,\n",
       "        -0.0188, -0.0048])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean[:10] # should NOT be all zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:26:36 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating on the test set <span style=\"font-weight: bold\">(</span>stats set via <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">reset_bn_stats</span><span style=\"font-weight: bold\">()</span>!                 <a href=\"file:///tmp/ipykernel_12722/310569331.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_12722/310569331.py#1\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:26:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating on the test set \u001b[1m(\u001b[0mstats set via \u001b[1;35mreset_bn_stats\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m!                 \u001b]8;id=710974;file:///tmp/ipykernel_12722/310569331.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=410665;file:///tmp/ipykernel_12722/310569331.py#1\u001b\\\u001b[2m1\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 99/99 [00:24<00:00,  4.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         acc/test          </span><span style=\"color: #800080; text-decoration-color: #800080\">   0.019952494651079178    </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         loss/test         </span><span style=\"color: #800080; text-decoration-color: #800080\">     4.691280841827393     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m  0.019952494651079178   \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        loss/test        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4.691280841827393    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc/test': 0.019952494651079178, 'loss/test': 4.691280841827393}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pylogger.info(\"Evaluating on the test set (stats set via reset_bn_stats()!)\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean = dataset_stats[dataset_name][\"conv1.bn\"][\"running_mean\"]\n",
    "model.encoder.model.visual.conv1.bn.running_var = dataset_stats[dataset_name][\"conv1.bn\"][\"running_var\"]\n",
    "\n",
    "for i in range(12):\n",
    "    model.encoder.model.visual.transformer.resblocks[i].attn.out_proj.bn.running_mean = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.attn.out_proj.bn\"][\"running_mean\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_fc.bn.running_mean = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.mlp.c_fc.bn\"][\"running_mean\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_proj.bn.running_mean = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.mlp.c_proj.bn\"][\"running_mean\"]\n",
    "    \n",
    "    model.encoder.model.visual.transformer.resblocks[i].attn.out_proj.bn.running_var = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.attn.out_proj.bn\"][\"running_var\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_fc.bn.running_var = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.mlp.c_fc.bn\"][\"running_var\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_proj.bn.running_var = dataset_stats[dataset_name][f\"transformer.resblocks.{i}.mlp.c_proj.bn\"][\"running_var\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 14:28:46 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating on the test set! <span style=\"font-weight: bold\">(</span>stats set via dataset_stats<span style=\"font-weight: bold\">)</span>                   <a href=\"file:///tmp/ipykernel_12722/1970705047.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_12722/1970705047.py#1\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 14:28:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating on the test set! \u001b[1m(\u001b[0mstats set via dataset_stats\u001b[1m)\u001b[0m                   \u001b]8;id=776335;file:///tmp/ipykernel_12722/1970705047.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=737522;file:///tmp/ipykernel_12722/1970705047.py#1\u001b\\\u001b[2m1\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 99/99 [00:24<00:00,  4.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         acc/test          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.02351543866097927    </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         loss/test         </span><span style=\"color: #800080; text-decoration-color: #800080\">    4.6658124923706055     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.02351543866097927   \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        loss/test        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   4.6658124923706055    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc/test': 0.02351543866097927, 'loss/test': 4.6658124923706055}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pylogger.info(\"Evaluating on the test set! (stats set via dataset_stats)\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
