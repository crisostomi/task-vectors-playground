{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/KS_2TB/PARA/Projects/task-vectors-playground/src/tvp/data/datamodule.py:193: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import Callback\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "from nn_core.common.utils import enforce_tags, seed_index_everything\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "\n",
    "# Force the execution of __init__.py if this file is executed directly.\n",
    "import tvp  # noqa\n",
    "from tvp.data.datamodule import MetaData\n",
    "from tvp.data.datasets.registry import get_dataset\n",
    "from tvp.task_vectors.task_vectors import TaskVector\n",
    "from tvp.utils.io_utils import load_model_from_artifact\n",
    "from tvp.utils.utils import build_callbacks\n",
    "from torch.nn.utils import vector_to_parameters\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pylogger = logging.getLogger(__name__)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"task_vectors\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1608637542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-30 18:22:21 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Setting seed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608637542</span> from seeds<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-30 18:22:21\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Setting seed \u001b[1;36m1608637542\u001b[0m from seeds\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                         \u001b]8;id=506654;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=125355;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tags: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'dev'</span><span style=\"font-weight: bold\">]</span>                                                  <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">96</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tags: \u001b[1m[\u001b[0m\u001b[32m'dev'\u001b[0m\u001b[1m]\u001b[0m                                                  \u001b]8;id=507214;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552910;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Restoring with mode: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"font-weight: bold\">&gt;</span>                                         <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.resume</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Restoring with mode: \u001b[1m<\u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1m>\u001b[0m                                         \u001b]8;id=346224;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\u001b\\\u001b[2mnn_core.resume\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130475;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\u001b\\\u001b[2m122\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">WandbLogger</span><span style=\"font-weight: bold\">&gt;</span>                                   <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.model_logging</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating \u001b[1m<\u001b[0m\u001b[1;95mWandbLogger\u001b[0m\u001b[1m>\u001b[0m                                   \u001b]8;id=170108;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\u001b\\\u001b[2mnn_core.model_logging\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=507338;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Failed to detect the name of this notebook, you can set it manually  <a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">wandb.jupyter</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py#224\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         with the WANDB_NOTEBOOK_NAME environment variable to enable code     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         saving.                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Failed to detect the name of this notebook, you can set it manually  \u001b]8;id=25814;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py\u001b\\\u001b[2mwandb.jupyter\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=720665;file:///mnt/KS_2TB/PARA/Resources/miniconda3/envs/tvp/lib/python3.11/site-packages/wandb/jupyter.py#224\u001b\\\u001b[2m224\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         with the WANDB_NOTEBOOK_NAME environment variable to enable code     \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         saving.                                                              \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdansolombrino\u001b[0m (\u001b[33mgladia\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240530_182222-47o0uy9v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gladia/task-vectors-playground/runs/47o0uy9v' target=\"_blank\">classic-pyramid-199</a></strong> to <a href='https://wandb.ai/gladia/task-vectors-playground' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gladia/task-vectors-playground' target=\"_blank\">https://wandb.ai/gladia/task-vectors-playground</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gladia/task-vectors-playground/runs/47o0uy9v' target=\"_blank\">https://wandb.ai/gladia/task-vectors-playground/runs/47o0uy9v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "cfg.core.tags = enforce_tags(cfg.core.get(\"tags\", None))\n",
    "\n",
    "template_core: NNTemplateCore = NNTemplateCore(\n",
    "    restore_cfg=cfg.train.get(\"restore\", None),\n",
    ")\n",
    "logger: NNLogger = NNLogger(logging_cfg=cfg.train.logging, cfg=cfg, resume_id=template_core.resume_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResetConv(nn.Module):\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        self.out_channels = conv.out_channels\n",
    "        self.conv = conv\n",
    "        self.bn = nn.BatchNorm2d(self.out_channels)\n",
    "        self.rescale = False\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_var, eps=1e-5):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        goal_std = (goal_var + eps).sqrt()\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.rescale:\n",
    "            x = self.bn(x)\n",
    "        else:\n",
    "            self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResetLinear(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        # print(f\"\\n\\n[ResetLinear] layer: {layer}\\n\\n\")\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.out_features)\n",
    "        self.weight = layer.weight\n",
    "        self.bias = layer.bias\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [L, N, C] (in torch.nn.BatchNorm1d doc notation)\n",
    "        x = self.layer(x)\n",
    "\n",
    "        # match current shape to shape required by BatchNorm1d\n",
    "        x = x.permute(1, 2, 0)\n",
    "        # x.shape: [N, C, L] (in torch.nn.BatchNorm1d doc notation)\n",
    "\n",
    "        x = self.bn(x)\n",
    "\n",
    "        # match current shape to shape required by Linear\n",
    "        x = x.permute(2, 0, 1)\n",
    "        # x.shape: [L, N, C] (in torch.nn.BatchNorm1d doc notation)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResetLayerNorm(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.normalized_shape[0])\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "def replace_layers(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, ResetConv(child))\n",
    "        # elif isinstance(child, nn.LayerNorm):\n",
    "        #     setattr(module, name, ResetLayerNorm(child))\n",
    "        elif isinstance(child, nn.Linear):\n",
    "            setattr(module, name, ResetLinear(child))\n",
    "        else:\n",
    "            replace_layers(child)\n",
    "\n",
    "\n",
    "def make_tracked_net(model):\n",
    "    tracked_model = copy.deepcopy(model)\n",
    "    replace_layers(tracked_model.model.visual)\n",
    "    return tracked_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap and compute stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def reset_bn_stats(model, epochs, loader):\n",
    "    \"\"\"\n",
    "    Reset batchnorm stats. We use the train loader with data augmentation as this gives better results.\n",
    "    \"\"\"\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None  # use simple average\n",
    "            m.reset_running_stats()\n",
    "\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader):\n",
    "                if isinstance(batch, Dict):\n",
    "                    input = batch[\"x\"]\n",
    "                else:\n",
    "                    input = batch[0]\n",
    "                    # print(f\"[reset_bn_stats] input.shape before model(): {input.shape}\")\n",
    "                out = model(input.cuda())\n",
    "                # print(f\"[reset_bn_stats] out.shape after model()   : {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'CIFAR100'\n",
    "dataset_name = cfg.nn.data.train_dataset.replace(\"Val\", \"\")\n",
    "finetuned_model = finetuned_models[dataset_name]\n",
    "tracked_finetuned_model = make_tracked_net(finetuned_models[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_bn_stats(tracked_finetuned_model.cuda(), 1, dataset.train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_finetuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters())\n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [\n",
    "    TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_task_vector(model, task_vector):\n",
    "    model.load_state_dict({k: v + task_vector[k] for k, v in model.state_dict().items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack(\n",
    "        [flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model)\n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{cfg.nn.data.dataset.dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=model.encoder.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylogger.info(\"Evaluating on the training set\")\n",
    "# trainer.test(model=model, dataloaders=dataset.train_loader)\n",
    "\n",
    "pylogger.info(\"Evaluating on the test set!\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this accuracy in mind, as it will be used as baseline to compare all upcoming experiments against"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset stats\n",
    "\n",
    "Compute and export mean and std for every dataset, if not already present on disk.<br>\n",
    "Otherwhise, load mean and std for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the full path of a module\n",
    "def get_module_path(module, parent_name=\"\"):\n",
    "    if parent_name:\n",
    "        return f\"{parent_name}.{module._get_name()}\"\n",
    "    return module._get_name()\n",
    "\n",
    "\n",
    "# Define a recursive function to collect batch norm stats from 'Reset' layers\n",
    "def collect_bn_stats(model, parent_name=\"\"):\n",
    "    bn_stats = {}\n",
    "    for name, module in model.named_children():\n",
    "        # Construct the full path of the current module\n",
    "        module_path = f\"{parent_name}.{name}\" if parent_name else name\n",
    "\n",
    "        # Check for batch normalization layers within Reset layers\n",
    "        if isinstance(module, ResetConv) or isinstance(module, ResetLinear):\n",
    "            for sub_name, sub_module in module.named_children():\n",
    "                if isinstance(sub_module, nn.BatchNorm2d) or isinstance(sub_module, nn.BatchNorm1d):\n",
    "                    bn_stats[f\"{module_path}.{sub_name}\"] = {\n",
    "                        \"running_mean\": sub_module.running_mean.clone().detach(),\n",
    "                        \"running_var\": sub_module.running_var.clone().detach(),\n",
    "                        \"num_batches_tracked\": sub_module.num_batches_tracked.clone().detach(),\n",
    "                    }\n",
    "        # Recursively check submodules\n",
    "        bn_stats.update(collect_bn_stats(module, module_path))\n",
    "\n",
    "    return bn_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stats = {}  # S in board pictures\n",
    "\n",
    "# if \"./dataset_stats.pth\" is on disk, do not compute stats!\n",
    "populate_stats = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_stats:\n",
    "    # TODO once done, try without it, as all methods use copy.deepcopy, so hygiene should be guaranteed\n",
    "\n",
    "    import copy\n",
    "\n",
    "    zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "    zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "    finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "    finetuned_models = {\n",
    "        dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "        for dataset in cfg.task_vectors.to_apply\n",
    "    }\n",
    "\n",
    "    zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_stats:\n",
    "    for dataset_name in cfg.task_vectors.to_apply:\n",
    "        print(f\"[dataset_name]: {dataset_name}\\n\")\n",
    "\n",
    "        # begin load the dataset\n",
    "\n",
    "        dataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            preprocess_fn=zeroshot_model.train_preprocess,\n",
    "            location=cfg.nn.data.data_path,\n",
    "            batch_size=cfg.nn.data.batch_size.train,\n",
    "        )\n",
    "\n",
    "        #   end load the dataset\n",
    "\n",
    "        finetuned_model = copy.deepcopy(finetuned_models[dataset_name])\n",
    "\n",
    "        # begin compute layer-wise statistics\n",
    "\n",
    "        tracked_finetuned_model = make_tracked_net(finetuned_model)\n",
    "\n",
    "        reset_bn_stats(tracked_finetuned_model.cuda(), 1, dataset.train_loader)\n",
    "\n",
    "        # end compute layer-wise statistics\n",
    "\n",
    "        # begin store layer-wise statistics\n",
    "\n",
    "        dataset_stats[dataset_name] = collect_bn_stats(tracked_finetuned_model.model.visual)\n",
    "\n",
    "        # end store layer-wise statistics\n",
    "\n",
    "    torch.save(dataset_stats, \"./dataset_stats.pth\")\n",
    "\n",
    "else:\n",
    "    print(f\"Loading dataset stats from './dataset_stats.pth'...\")\n",
    "\n",
    "    dataset_stats = torch.load(\"./dataset_stats.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchor_batches = 1\n",
    "\n",
    "anchors = {}\n",
    "\n",
    "populate_anchors = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_anchors:\n",
    "    # TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "    import copy\n",
    "\n",
    "    zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "    zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "    finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "    finetuned_models = {\n",
    "        dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "        for dataset in cfg.task_vectors.to_apply\n",
    "    }\n",
    "\n",
    "    zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchors computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_anchors:\n",
    "    for dataset_name in cfg.task_vectors.to_apply:\n",
    "        print(f\"[dataset_name]: {dataset_name}\\n\")\n",
    "\n",
    "        dataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            preprocess_fn=zeroshot_model.train_preprocess,\n",
    "            location=cfg.nn.data.data_path,\n",
    "            batch_size=cfg.nn.data.batch_size.train,\n",
    "        )\n",
    "\n",
    "        model: nn.Module = copy.deepcopy(finetuned_models[dataset_name])\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for id, train_batch in enumerate(dataset.train_loader):\n",
    "                if id == n_anchor_batches:\n",
    "                    break\n",
    "\n",
    "                if isinstance(train_batch, Dict):\n",
    "                    input: torch.Tensor = train_batch[\"x\"]\n",
    "                else:\n",
    "                    input: torch.Tensor = train_batch[0]\n",
    "\n",
    "                anchors[dataset_name] = model.cuda()(input.cuda())\n",
    "\n",
    "    torch.save(anchors, \"./anchors.pth\")\n",
    "\n",
    "else:\n",
    "    print(f\"Loading anchors from './anchors.pth'...\")\n",
    "\n",
    "    anchors = torch.load(\"./anchors.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_tensor = torch.stack([anchors[dataset_name] for dataset_name in anchors.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate((anchors.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "import copy\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"GTSRB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters())\n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [\n",
    "    TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack(\n",
    "        [flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model)\n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate (naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylogger.info(\"Evaluating on the test set!\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (our method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once done, try without it, as all methods use copy.deepcopy, so hygene should be guaranteed\n",
    "\n",
    "import copy\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters())\n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [\n",
    "    TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack(\n",
    "        [flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model)\n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model for REPAIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this here, as the classification head may have layers that may be detected as REPAIRable, even tho we don't want to repair them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_finetuned_model = make_tracked_net(task_equipped_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate (our method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=tracked_finetuned_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(similarity: torch.Tensor):\n",
    "    # similarity.shape: [B, M]\n",
    "\n",
    "    # Get the index of the highest similarity for each element in the batch\n",
    "    max_similarity_indices = torch.argmax(similarity, dim=1)  # shape: [B]\n",
    "\n",
    "    # Perform majority voting\n",
    "    majority_vote = Counter(max_similarity_indices.cpu().numpy()).most_common(1)[0][0]\n",
    "\n",
    "    return majority_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_based_similarity(batch: torch.Tensor, anchors_tensor: torch.Tensor):\n",
    "    # batch.shape: [B, D]\n",
    "    # anchors_tensor.shape: [M, K, D]\n",
    "\n",
    "    M, K, D = anchors_tensor.shape\n",
    "    B = batch.shape[0]\n",
    "\n",
    "    # Compute centroids of each anchor set\n",
    "    centroids = anchors_tensor.mean(dim=1)  # shape: [M, D]\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    # Normalize batch and centroids\n",
    "    batch_norm = F.normalize(batch, p=2, dim=1)  # shape: [B, D]\n",
    "    centroids_norm = F.normalize(centroids, p=2, dim=1)  # shape: [M, D]\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity = torch.mm(batch_norm, centroids_norm.t())  # shape: [B, M]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_wise_majority_votes = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate through the test data loader and compute point-to-set distances\n",
    "for id, test_batch in tqdm(list(enumerate(dataset.test_loader))):\n",
    "    with torch.no_grad():\n",
    "        if isinstance(test_batch, dict):\n",
    "            input: torch.Tensor = test_batch[\"x\"]\n",
    "        else:\n",
    "            input: torch.Tensor = test_batch[0]\n",
    "\n",
    "        emb = finetuned_models[dataset_name].cuda()(input.cuda())  # [B, D]\n",
    "        # print(f\"[emb]: {emb.shape}\")\n",
    "\n",
    "        similarities = centroid_based_similarity(emb, anchors_tensor)\n",
    "        # print(f\"[similarities]: {similarities.shape}\")\n",
    "\n",
    "        batch_wise_majority_votes.append(majority_voting(similarities))\n",
    "        # print(f\"[majority_vote]: {batch_wise_majority_votes[-1]}\")\n",
    "\n",
    "batch_wise_majority_votes = np.asarray(batch_wise_majority_votes)\n",
    "most_similar_dataset_id = Counter(batch_wise_majority_votes).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_dataset_name = list(anchors.keys())[most_similar_dataset_id]\n",
    "most_similar_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_dataset = get_dataset(\n",
    "    dataset_name=most_similar_dataset_name,\n",
    "    preprocess_fn=model.encoder.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean[:10]  # should be all zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_bn_stats(model.cuda(), 1, most_similar_dataset.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean[:10]  # should NOT be all zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylogger.info(\"Evaluating on the test set (stats set via reset_bn_stats()!)\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.model.visual.conv1.bn.running_mean = dataset_stats[most_similar_dataset_name][\"conv1.bn\"][\"running_mean\"]\n",
    "model.encoder.model.visual.conv1.bn.running_var = dataset_stats[most_similar_dataset_name][\"conv1.bn\"][\"running_var\"]\n",
    "\n",
    "for i in range(12):\n",
    "    model.encoder.model.visual.transformer.resblocks[i].attn.out_proj.bn.running_mean = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.attn.out_proj.bn\"\n",
    "    ][\"running_mean\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_fc.bn.running_mean = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.mlp.c_fc.bn\"\n",
    "    ][\"running_mean\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_proj.bn.running_mean = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.mlp.c_proj.bn\"\n",
    "    ][\"running_mean\"]\n",
    "\n",
    "    model.encoder.model.visual.transformer.resblocks[i].attn.out_proj.bn.running_var = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.attn.out_proj.bn\"\n",
    "    ][\"running_var\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_fc.bn.running_var = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.mlp.c_fc.bn\"\n",
    "    ][\"running_var\"]\n",
    "    model.encoder.model.visual.transformer.resblocks[i].mlp.c_proj.bn.running_var = dataset_stats[most_similar_dataset_name][\n",
    "        f\"transformer.resblocks.{i}.mlp.c_proj.bn\"\n",
    "    ][\"running_var\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylogger.info(\"Evaluating on the test set! (stats set via dataset_stats)\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
