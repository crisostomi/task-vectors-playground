{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from lightning.pytorch import Callback\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "from nn_core.common.utils import enforce_tags, seed_index_everything\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "\n",
    "# Force the execution of __init__.py if this file is executed directly.\n",
    "import tvp  # noqa\n",
    "from tvp.data.datamodule import MetaData\n",
    "from tvp.data.datasets.registry import get_dataset\n",
    "from tvp.task_vectors.task_vectors import TaskVector\n",
    "from tvp.utils.io_utils import load_model_from_artifact\n",
    "from tvp.utils.utils import build_callbacks\n",
    "from torch.nn.utils import vector_to_parameters\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "pylogger = logging.getLogger(__name__)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"task_vectors\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1608637542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:31 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Setting seed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608637542</span> from seeds<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                         <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Setting seed \u001b[1;36m1608637542\u001b[0m from seeds\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                         \u001b]8;id=323618;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=918782;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tags: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'dev'</span><span style=\"font-weight: bold\">]</span>                                                  <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">96</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tags: \u001b[1m[\u001b[0m\u001b[32m'dev'\u001b[0m\u001b[1m]\u001b[0m                                                  \u001b]8;id=30561;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398255;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Restoring with mode: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"font-weight: bold\">&gt;</span>                                         <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.resume</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Restoring with mode: \u001b[1m<\u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1m>\u001b[0m                                         \u001b]8;id=852900;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py\u001b\\\u001b[2mnn_core.resume\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721902;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/resume.py#122\u001b\\\u001b[2m122\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">WandbLogger</span><span style=\"font-weight: bold\">&gt;</span>                                   <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.model_logging</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating \u001b[1m<\u001b[0m\u001b[1;95mWandbLogger\u001b[0m\u001b[1m>\u001b[0m                                   \u001b]8;id=130475;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py\u001b\\\u001b[2mnn_core.model_logging\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464412;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/model_logging.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "cfg.core.tags = enforce_tags(cfg.core.get(\"tags\", None))\n",
    "\n",
    "template_core: NNTemplateCore = NNTemplateCore(\n",
    "    restore_cfg=cfg.train.get(\"restore\", None),\n",
    ")\n",
    "logger: NNLogger = NNLogger(logging_cfg=cfg.train.logging, cfg=cfg, resume_id=template_core.resume_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:32 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_pt:latest                   <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_pt:latest                   \u001b]8;id=224430;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=170108;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_pt:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:35 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=6511;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500215;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:37 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_Cars_0:latest               <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_Cars_0:latest               \u001b]8;id=813694;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=822996;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_Cars_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:40 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:40\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=459697;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850440;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:42 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_CIFAR100_0:latest           <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_CIFAR100_0:latest           \u001b]8;id=560796;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=355368;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_CIFAR100_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:44 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=255163;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=527597;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:46 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_DTD_0:latest                <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_DTD_0:latest                \u001b]8;id=491560;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836233;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_DTD_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:48 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:48\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=349771;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=650903;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:50 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_EuroSAT_0:latest            <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:50\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_EuroSAT_0:latest            \u001b]8;id=511817;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=351483;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_EuroSAT_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:53 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=8941;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=219438;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:55 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_GTSRB_0:latest              <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_GTSRB_0:latest              \u001b]8;id=833390;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=889220;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_GTSRB_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:57 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=782401;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=829130;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:47:59 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_MNIST_0:latest              <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:47:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_MNIST_0:latest              \u001b]8;id=172798;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=315957;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_MNIST_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:48:03 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:48:03\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=83169;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=782604;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:48:04 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_RESISC45_0:latest           <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:48:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_RESISC45_0:latest           \u001b]8;id=76642;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=996500;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_RESISC45_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:48:07 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:48:07\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=717760;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270984;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:48:08 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_SVHN_0:latest               <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:48:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_SVHN_0:latest               \u001b]8;id=264469;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104463;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ViT-B-16_SVHN_0:latest, 426.51MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-B-16 pre-trained weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-25 18:48:11 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading pretrained ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> from OpenAI.                                       <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">root</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-25 18:48:11\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading pretrained ViT-B-\u001b[1;36m16\u001b[0m from OpenAI.                                       \u001b]8;id=8625;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py\u001b\\\u001b[2mroot\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=724270;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/factory.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "zeroshot_identifier = f\"{cfg.nn.module.model.model_name}_pt\"\n",
    "\n",
    "zeroshot_model = load_model_from_artifact(artifact_path=f\"{zeroshot_identifier}:latest\", run=logger.experiment)\n",
    "\n",
    "finetuned_id_fn = lambda dataset: f\"{cfg.nn.module.model.model_name}_{dataset}_{cfg.seed_index}:latest\"\n",
    "\n",
    "finetuned_models = {\n",
    "    dataset: load_model_from_artifact(artifact_path=finetuned_id_fn(dataset), run=logger.experiment)\n",
    "    for dataset in cfg.task_vectors.to_apply\n",
    "}\n",
    "\n",
    "zeroshot_orig_weights = copy.deepcopy(zeroshot_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResetConv(nn.Module):\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        self.out_channels = conv.out_channels\n",
    "        self.conv = conv\n",
    "        self.bn = nn.BatchNorm2d(self.out_channels)\n",
    "        self.rescale = False\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_var, eps=1e-5):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        goal_std = (goal_var + eps).sqrt()\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.rescale:\n",
    "            x = self.bn(x)\n",
    "        else:\n",
    "            self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ResetLinear(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.out_features)\n",
    "        self.weight = layer.weight\n",
    "        self.bias = layer.bias\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return self.bn(x)\n",
    "    \n",
    "class ResetLayerNorm(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm1d(layer.normalized_shape[0])\n",
    "\n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "def replace_layers(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, ResetConv(child))\n",
    "        # elif isinstance(child, nn.LayerNorm):\n",
    "        #     setattr(module, name, ResetLayerNorm(child))\n",
    "        elif isinstance(child, nn.Linear):\n",
    "            setattr(module, name, ResetLinear(child))\n",
    "        else:\n",
    "            replace_layers(child)\n",
    "\n",
    "\n",
    "def make_tracked_net(model):\n",
    "    tracked_model = copy.deepcopy(model)\n",
    "    replace_layers(tracked_model.model.visual)\n",
    "    return tracked_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_task_statistics(model, endpoint_models):\n",
    "#     for m_interp, *endpoint_modules in zip(model_to_repair.modules(), *[model.modules() for model in endpoint_models]):\n",
    "#         if isinstance(m_interp, (ResetConv, ResetLayerNorm, ResetLinear)):\n",
    "#             mu_endpoints = torch.stack([m.bn.running_mean for m in endpoint_modules])\n",
    "#             goal_mean = mu_endpoints.mean(dim=0)\n",
    "#             var_endpoints = torch.stack([m.bn.running_var for m in endpoint_modules])\n",
    "#             goal_var = var_endpoints.mean(dim=0)\n",
    "#             m_interp.set_stats(goal_mean, goal_var)\n",
    "#             m_interp.rescale = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap and compute stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=zeroshot_model.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_bn_stats(model, epochs, loader):\n",
    "    \"\"\"\n",
    "    Reset batchnorm stats. We use the train loader with data augmentation as this gives better results.\n",
    "    \"\"\"\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None  # use simple average\n",
    "            m.reset_running_stats()\n",
    "\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                if isinstance(batch, Dict):\n",
    "                    input = batch[\"x\"]\n",
    "                else:\n",
    "                    input = batch[0]\n",
    "                _ = model(input.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CIFAR100'\n",
    "finetuned_model = finetuned_models[dataset_name]\n",
    "tracked_finetuned_model = make_tracked_net(finetuned_models[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisualTransformer(\n",
       "  (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model.model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 197, 768])\n",
      "torch.Size([197, 128, 768])\n",
      "torch.Size([197, 128, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 128 elements not 3072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreset_bn_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_finetuned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 20\u001b[0m, in \u001b[0;36mreset_bn_stats\u001b[0;34m(model, epochs, loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/modules/encoder.py:49\u001b[0m, in \u001b[0;36mImageEncoder.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/modules/encoder.py:46\u001b[0m, in \u001b[0;36mImageEncoder.forward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/model.py:633\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/model.py:473\u001b[0m, in \u001b[0;36mVisualTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# TODO: check this\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    475\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# LND -> NLD\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/model.py:394\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 394\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/open_clip/model.py:363\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, attn_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    362\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x), attn_mask\u001b[38;5;241m=\u001b[39mattn_mask))\n\u001b[0;32m--> 363\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[40], line 38\u001b[0m, in \u001b[0;36mResetLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(x)\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvp/lib/python3.11/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 128 elements not 3072"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(tracked_finetuned_model.cuda(), 1, dataset.train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageEncoder(\n",
       "  (model): CLIP(\n",
       "    (visual): VisualTransformer(\n",
       "      (conv1): ResetConv(\n",
       "        (conv): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_attn): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ln): Identity()\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 512)\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracked_finetuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda model: parameters_to_vector(model.parameters()) \n",
    "\n",
    "zeroshot_vec = flatten(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = [TaskVector.from_models(zeroshot_model, finetuned_models[dataset]) for dataset in cfg.task_vectors.to_apply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_task_vector(model, task_vector):\n",
    "    model.load_state_dict({k: v + task_vector[k] for k, v in model.state_dict().items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    task_vectors = torch.stack([flatten(finetuned_models[dataset]) - zeroshot_vec for dataset in cfg.task_vectors.to_apply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors_sum = torch.sum(task_vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "\n",
    "multi_task_vector = task_vectors_sum / len(task_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model = copy.deepcopy(zeroshot_model) \n",
    "vector_to_parameters(multi_task_vector, delta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_equipped_model = copy.deepcopy(zeroshot_model)\n",
    "apply_task_vector(task_equipped_model, delta_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-24 09:21:57 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading model from artifact ViT-B-16_CIFAR100_head:latest        <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.io_utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-24 09:21:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading model from artifact ViT-B-16_CIFAR100_head:latest        \u001b]8;id=491560;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py\u001b\\\u001b[2mtvp.utils.io_utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836233;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/io_utils.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "/home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "  rank_zero_warn(\n",
      "/home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classifier'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "classification_head_identifier = f\"{cfg.nn.module.model.model_name}_{cfg.nn.data.dataset.dataset_name}_head\"\n",
    "classification_head = load_model_from_artifact(\n",
    "    artifact_path=f\"{classification_head_identifier}:latest\", run=logger.experiment\n",
    ")\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.nn.module, encoder=task_equipped_model, classifier=classification_head, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1608637542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-24 09:21:59 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Setting seed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608637542</span> from seeds<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                         <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nn_core.common.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-24 09:21:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Setting seed \u001b[1;36m1608637542\u001b[0m from seeds\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                         \u001b]8;id=323618;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py\u001b\\\u001b[2mnn_core.common.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=918782;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/nn_core/common/utils.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2024-05-24 09:22:00 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EarlyStopping</span><span style=\"font-weight: bold\">&gt;</span>                                    <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2024-05-24 09:22:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mEarlyStopping\u001b[0m\u001b[1m>\u001b[0m                                    \u001b]8;id=30561;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398255;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelCheckpoint</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mModelCheckpoint\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=852900;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721902;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LearningRateMonitor</span><span style=\"font-weight: bold\">&gt;</span>                              <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mLearningRateMonitor\u001b[0m\u001b[1m>\u001b[0m                              \u001b]8;id=130475;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464412;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Adding callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">TQDMProgressBar</span><span style=\"font-weight: bold\">&gt;</span>                                  <a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">tvp.utils.utils</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Adding callback \u001b[1m<\u001b[0m\u001b[1;95mTQDMProgressBar\u001b[0m\u001b[1m>\u001b[0m                                  \u001b]8;id=224430;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py\u001b\\\u001b[2mtvp.utils.utils\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=170108;file:///media/donato/Extra-storage/Code/model-merging/task-vectors-playground/src/tvp/utils/utils.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating the <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">&gt;</span>                                                <a href=\"file:///tmp/ipykernel_3776263/2238203488.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3776263/2238203488.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Instantiating the \u001b[1m<\u001b[0m\u001b[1;95mTrainer\u001b[0m\u001b[1m>\u001b[0m                                                \u001b]8;id=6511;file:///tmp/ipykernel_3776263/2238203488.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500215;file:///tmp/ipykernel_3776263/2238203488.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>        <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m        \u001b]8;id=813694;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=822996;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores      <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores      \u001b]8;id=459697;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850440;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> IPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> IPUs           <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m IPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m IPUs           \u001b]8;id=560796;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=355368;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs           <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs           \u001b]8;id=255163;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=527597;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">val_check_interval</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">)</span>` was         <a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">lightning.pytorch.utilities.rank_zero</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         configured so validation will run at the end  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         of the training epoch..                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mval_check_interval\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m` was         \u001b]8;id=491560;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mlightning.pytorch.utilities.rank_zero\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836233;file:///home/donato/miniconda3/envs/tvp/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         configured so validation will run at the end  \u001b[2m                                        \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         of the training epoch..                       \u001b[2m                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_index_everything(cfg)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    cfg.nn.data.train_dataset,\n",
    "    preprocess_fn=model.encoder.train_preprocess,\n",
    "    location=cfg.nn.data.data_path,\n",
    "    batch_size=cfg.nn.data.batch_size.train,\n",
    ")\n",
    "\n",
    "callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "pylogger.info(\"Instantiating the <Trainer>\")\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=storage_dir,\n",
    "    plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    **cfg.train.trainer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating on the test set!                                                 <a href=\"file:///tmp/ipykernel_3776263/1153275028.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__main__</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3776263/1153275028.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating on the test set!                                                 \u001b]8;id=349771;file:///tmp/ipykernel_3776263/1153275028.py\u001b\\\u001b[2m__main__\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=650903;file:///tmp/ipykernel_3776263/1153275028.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 40/40 [00:10<00:00,  3.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">   Runningstage.testing    </span><span style=\"font-weight: bold\">                           </span>\n",
       "<span style=\"font-weight: bold\">          metric           </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         acc/test          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.7657999992370605     </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         loss/test         </span><span style=\"color: #800080; text-decoration-color: #800080\">    1.0084812641143799     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m\u001b[1m                           \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.7657999992370605    \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        loss/test        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   1.0084812641143799    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc/test': 0.7657999992370605, 'loss/test': 1.0084812641143799}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pylogger.info(\"Evaluating on the training set\")\n",
    "# trainer.test(model=model, dataloaders=dataset.train_loader)\n",
    "\n",
    "pylogger.info(\"Evaluating on the test set!\")\n",
    "trainer.test(model=model, dataloaders=dataset.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
